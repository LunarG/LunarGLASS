
Top IR:
; ModuleID = 'Glslang'

%ubName = type { <2 x float> }
%outName = type { <4 x float> }

@inf = global <2 x float> zeroinitializer
@ing = global <2 x float> zeroinitializer
@inch = global <2 x float> zeroinitializer
@iArray = external addrspace(1) constant [5 x i32]
@index = external addrspace(2) constant i32
@sArray = external addrspace(1) constant [4 x i32]
@ubInst = external addrspace(2) constant [4 x %ubName]
@color = internal constant [4 x <2 x i32>] [<2 x i32> <i32 1, i32 1>, <2 x i32> <i32 2, i32 2>, <2 x i32> <i32 3, i32 3>, <2 x i32> <i32 4, i32 4>]
@outInst = global %outName zeroinitializer
@bufSamp1 = external addrspace(1) constant i32
@bufSamp2 = external addrspace(1) constant i32
@bufSamp3 = external addrspace(1) constant i32
@bufSamp4 = external addrspace(1) constant i32
@bufSamp5 = external addrspace(1) constant i32
@bufSamp6 = external addrspace(1) constant i32
@CA4 = external addrspace(1) constant i32
@CA5 = external addrspace(1) constant i32
@CA6 = external addrspace(1) constant i32
@CA7 = external addrspace(1) constant i32
@CA1 = external addrspace(1) constant i32
@CA2 = external addrspace(1) constant i32
@CA3 = external addrspace(1) constant i32
@samp2DMSA = external addrspace(1) constant i32
@samp2DMSAi = external addrspace(1) constant i32
@samp2DMSAu = external addrspace(1) constant i32
@im2Di = external addrspace(1) constant i32
@P = external addrspace(2) constant <2 x i32>
@im2Du = external addrspace(1) constant i32
@im2Df = external addrspace(1) constant i32
@gl_VertexID = global i32 0
@gl_InstanceID = global i32 0

define fastcc void @main() {
entry:
  %constOffsets = alloca [4 x <2 x i32>]
  %color = alloca <4 x float>
  %p = alloca <2 x float>
  br label %mainBody

mainBody:                                         ; preds = %entry
  %0 = load <2 x float>* @inf
  %1 = load <2 x float>* @ing
  %2 = load <2 x float>* @inch
  %p2 = call <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float> %0, <2 x float> %1, <2 x float> %2), !gla.precision !83
  store <2 x float> %p2, <2 x float>* %p
  %3 = load i32 addrspace(2)* @index, !gla.uniform !14
  store <4 x float> zeroinitializer, <4 x float>* %color
  %4 = load i32 addrspace(2)* @index, !gla.uniform !14
  %5 = getelementptr [4 x i32] addrspace(1)* @sArray, i32 0, i32 %4
  %6 = load i32 addrspace(1)* %5, !gla.uniform !16
  %7 = load i32 addrspace(2)* @index, !gla.uniform !14
  %8 = getelementptr [4 x %ubName] addrspace(2)* @ubInst, i32 0, i32 %7, i32 0
  %9 = load <2 x float> addrspace(2)* %8, !gla.uniform !19
  %10 = load <2 x float>* @inf
  %11 = fptosi <2 x float> %10 to <2 x i32>, !gla.precision !83
  %color3 = call <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32 2, i32 %6, i32 320, <2 x float> %9, i32 undef, float undef, <2 x i32> %11), !gla.precision !83
  %12 = load <4 x float>* %color
  %color4 = fadd <4 x float> %12, %color3, !gla.precision !83
  store <4 x float> %color4, <4 x float>* %color
  %13 = load i32 addrspace(2)* @index, !gla.uniform !14
  %14 = getelementptr [4 x i32] addrspace(1)* @sArray, i32 0, i32 %13
  %15 = load i32 addrspace(1)* %14, !gla.uniform !16
  %16 = load <2 x float>* %p
  %17 = load [4 x <2 x i32>]* @color
  %18 = extractvalue [4 x <2 x i32>] %17, 0
  %19 = extractvalue [4 x <2 x i32>] %17, 1
  %20 = extractvalue [4 x <2 x i32>] %17, 2
  %21 = extractvalue [4 x <2 x i32>] %17, 3
  %color5 = call <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32 2, i32 %15, i32 8512, <2 x float> %16, i32 undef, float undef, <2 x i32> %18, <2 x i32> %19, <2 x i32> %20, <2 x i32> %21), !gla.precision !83
  %22 = load <4 x float>* %color
  %color6 = fadd <4 x float> %22, %color5, !gla.precision !83
  store <4 x float> %color6, <4 x float>* %color
  %23 = load <4 x float>* %color
  store <4 x float> %23, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %24 = call <4 x float> @"bufferT("()
  %25 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %26 = fadd <4 x float> %25, %24, !gla.precision !83
  store <4 x float> %26, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %27 = call <4 x float> @"CAT("()
  %28 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %29 = fadd <4 x float> %28, %27, !gla.precision !83
  store <4 x float> %29, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %30 = call <4 x float> @"MSA("()
  %31 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %32 = fadd <4 x float> %31, %30, !gla.precision !83
  store <4 x float> %32, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  call void @"goodImageAtom("()
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %mainBody
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"bufferT("() #0 {
entry:
  %v23 = alloca <4 x float>
  %v19 = alloca <4 x float>
  %v15 = alloca <4 x float>
  %v11 = alloca <4 x float>
  %v7 = alloca <4 x float>
  %v3 = alloca <4 x float>
  %s1 = alloca i32
  %v = alloca <4 x float>
  store <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float>* %v
  %0 = load i32 addrspace(1)* @bufSamp1, !gla.uniform !22
  %s12 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %0), !gla.precision !83
  store i32 %s12, i32* %s1
  %1 = load i32* %s1
  %2 = sitofp i32 %1 to float, !gla.precision !83
  %3 = load <4 x float>* %v3
  %4 = insertelement <4 x float> undef, float %2, i32 0, !gla.precision !83
  %5 = insertelement <4 x float> %4, float %2, i32 1, !gla.precision !83
  %6 = insertelement <4 x float> %5, float %2, i32 2, !gla.precision !83
  %7 = insertelement <4 x float> %6, float %2, i32 3, !gla.precision !83
  %8 = load <4 x float>* %v
  %v4 = fmul <4 x float> %8, %7, !gla.precision !83
  store <4 x float> %v4, <4 x float>* %v
  %9 = load i32 addrspace(1)* @bufSamp2, !gla.uniform !25
  %s16 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %9), !gla.precision !83
  store i32 %s16, i32* %s1
  %10 = load i32* %s1
  %11 = sitofp i32 %10 to float, !gla.precision !83
  %12 = load <4 x float>* %v7
  %13 = insertelement <4 x float> undef, float %11, i32 0, !gla.precision !83
  %14 = insertelement <4 x float> %13, float %11, i32 1, !gla.precision !83
  %15 = insertelement <4 x float> %14, float %11, i32 2, !gla.precision !83
  %16 = insertelement <4 x float> %15, float %11, i32 3, !gla.precision !83
  %17 = load <4 x float>* %v
  %v8 = fmul <4 x float> %17, %16, !gla.precision !83
  store <4 x float> %v8, <4 x float>* %v
  %18 = load i32 addrspace(1)* @bufSamp3, !gla.uniform !28
  %s110 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %18), !gla.precision !83
  store i32 %s110, i32* %s1
  %19 = load i32* %s1
  %20 = sitofp i32 %19 to float, !gla.precision !83
  %21 = load <4 x float>* %v11
  %22 = insertelement <4 x float> undef, float %20, i32 0, !gla.precision !83
  %23 = insertelement <4 x float> %22, float %20, i32 1, !gla.precision !83
  %24 = insertelement <4 x float> %23, float %20, i32 2, !gla.precision !83
  %25 = insertelement <4 x float> %24, float %20, i32 3, !gla.precision !83
  %26 = load <4 x float>* %v
  %v12 = fmul <4 x float> %26, %25, !gla.precision !83
  store <4 x float> %v12, <4 x float>* %v
  %27 = load i32 addrspace(1)* @bufSamp4, !gla.uniform !31
  %s114 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %27), !gla.precision !83
  store i32 %s114, i32* %s1
  %28 = load i32* %s1
  %29 = sitofp i32 %28 to float, !gla.precision !83
  %30 = load <4 x float>* %v15
  %31 = insertelement <4 x float> undef, float %29, i32 0, !gla.precision !83
  %32 = insertelement <4 x float> %31, float %29, i32 1, !gla.precision !83
  %33 = insertelement <4 x float> %32, float %29, i32 2, !gla.precision !83
  %34 = insertelement <4 x float> %33, float %29, i32 3, !gla.precision !83
  %35 = load <4 x float>* %v
  %v16 = fmul <4 x float> %35, %34, !gla.precision !83
  store <4 x float> %v16, <4 x float>* %v
  %36 = load i32 addrspace(1)* @bufSamp5, !gla.uniform !34
  %s118 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %36), !gla.precision !83
  store i32 %s118, i32* %s1
  %37 = load i32* %s1
  %38 = sitofp i32 %37 to float, !gla.precision !83
  %39 = load <4 x float>* %v19
  %40 = insertelement <4 x float> undef, float %38, i32 0, !gla.precision !83
  %41 = insertelement <4 x float> %40, float %38, i32 1, !gla.precision !83
  %42 = insertelement <4 x float> %41, float %38, i32 2, !gla.precision !83
  %43 = insertelement <4 x float> %42, float %38, i32 3, !gla.precision !83
  %44 = load <4 x float>* %v
  %v20 = fmul <4 x float> %44, %43, !gla.precision !83
  store <4 x float> %v20, <4 x float>* %v
  %45 = load i32 addrspace(1)* @bufSamp6, !gla.uniform !37
  %s122 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %45), !gla.precision !83
  store i32 %s122, i32* %s1
  %46 = load i32* %s1
  %47 = sitofp i32 %46 to float, !gla.precision !83
  %48 = load <4 x float>* %v23
  %49 = insertelement <4 x float> undef, float %47, i32 0, !gla.precision !83
  %50 = insertelement <4 x float> %49, float %47, i32 1, !gla.precision !83
  %51 = insertelement <4 x float> %50, float %47, i32 2, !gla.precision !83
  %52 = insertelement <4 x float> %51, float %47, i32 3, !gla.precision !83
  %53 = load <4 x float>* %v
  %v24 = fmul <4 x float> %53, %52, !gla.precision !83
  store <4 x float> %v24, <4 x float>* %v
  %54 = load i32 addrspace(1)* @bufSamp1, !gla.uniform !22
  %55 = load i32* %s1
  %v25 = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32 0, i32 %54, i32 32, i32 %55, i32 undef, float undef, i32 undef), !gla.precision !83
  %56 = load <4 x float>* %v
  %v26 = fmul <4 x float> %56, %v25, !gla.precision !83
  store <4 x float> %v26, <4 x float>* %v
  %57 = load i32 addrspace(1)* @bufSamp2, !gla.uniform !25
  %58 = load i32* %s1
  %v27 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %57, i32 32, i32 %58, i32 undef, float undef, i32 undef), !gla.precision !83
  %59 = sitofp <4 x i32> %v27 to <4 x float>, !gla.precision !83
  %60 = load <4 x float>* %v
  %v28 = fmul <4 x float> %60, %59, !gla.precision !83
  store <4 x float> %v28, <4 x float>* %v
  %61 = load i32 addrspace(1)* @bufSamp3, !gla.uniform !28
  %62 = load i32* %s1
  %v29 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %61, i32 32, i32 %62, i32 undef, float undef, i32 undef), !gla.precision !83
  %63 = uitofp <4 x i32> %v29 to <4 x float>, !gla.precision !83
  %64 = load <4 x float>* %v
  %v30 = fmul <4 x float> %64, %63, !gla.precision !83
  store <4 x float> %v30, <4 x float>* %v
  %65 = load <4 x float>* %v
  ret <4 x float> %65

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"CAT("() #0 {
entry:
  %v15 = alloca <4 x float>
  %v = alloca <4 x float>
  %iv = alloca <3 x i32>
  store <3 x i32> zeroinitializer, <3 x i32>* %iv
  %0 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %iv1 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %0, i32 1), !gla.precision !83
  %1 = load <3 x i32>* %iv
  %iv2 = add <3 x i32> %1, %iv1, !gla.precision !83
  store <3 x i32> %iv2, <3 x i32>* %iv
  %2 = load i32 addrspace(1)* @CA5, !gla.uniform !43
  %iv3 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %2, i32 1), !gla.precision !83
  %3 = load <3 x i32>* %iv
  %iv4 = add <3 x i32> %3, %iv3, !gla.precision !83
  store <3 x i32> %iv4, <3 x i32>* %iv
  %4 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %iv5 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %4, i32 1), !gla.precision !83
  %5 = load <3 x i32>* %iv
  %iv6 = add <3 x i32> %5, %iv5, !gla.precision !83
  store <3 x i32> %iv6, <3 x i32>* %iv
  %6 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %iv7 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %6, i32 1), !gla.precision !83
  %7 = load <3 x i32>* %iv
  %iv8 = add <3 x i32> %7, %iv7, !gla.precision !83
  store <3 x i32> %iv8, <3 x i32>* %iv
  %8 = load i32 addrspace(1)* @CA1, !gla.uniform !52
  %iv9 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %8), !gla.precision !83
  %9 = load <3 x i32>* %iv
  %iv10 = add <3 x i32> %9, %iv9, !gla.precision !83
  store <3 x i32> %iv10, <3 x i32>* %iv
  %10 = load i32 addrspace(1)* @CA2, !gla.uniform !55
  %iv11 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %10), !gla.precision !83
  %11 = load <3 x i32>* %iv
  %iv12 = add <3 x i32> %11, %iv11, !gla.precision !83
  store <3 x i32> %iv12, <3 x i32>* %iv
  %12 = load i32 addrspace(1)* @CA3, !gla.uniform !58
  %iv13 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %12), !gla.precision !83
  %13 = load <3 x i32>* %iv
  %iv14 = add <3 x i32> %13, %iv13, !gla.precision !83
  store <3 x i32> %iv14, <3 x i32>* %iv
  %14 = load <3 x i32>* %iv
  %15 = sitofp <3 x i32> %14 to <3 x float>, !gla.precision !83
  %16 = load <4 x float>* %v15
  %17 = extractelement <3 x float> %15, i32 0, !gla.precision !83
  %18 = insertelement <4 x float> %16, float %17, i32 0, !gla.precision !83
  %19 = extractelement <3 x float> %15, i32 1, !gla.precision !83
  %20 = insertelement <4 x float> %18, float %19, i32 1, !gla.precision !83
  %21 = extractelement <3 x float> %15, i32 2, !gla.precision !83
  %22 = insertelement <4 x float> %20, float %21, i32 2, !gla.precision !83
  %v16 = insertelement <4 x float> %22, float 1.000000e+00, i32 3, !gla.precision !83
  store <4 x float> %v16, <4 x float>* %v
  %23 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %v17 = call <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32 4, i32 %23, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %24 = load <4 x float>* %v
  %v18 = fmul <4 x float> %24, %v17, !gla.precision !83
  store <4 x float> %v18, <4 x float>* %v
  %25 = load i32 addrspace(1)* @CA5, !gla.uniform !43
  %v19 = call float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32 4, i32 %25, i32 154, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 3.000000e+00, float undef), !gla.precision !83
  %26 = load <4 x float>* %v
  %27 = insertelement <4 x float> undef, float %v19, i32 0, !gla.precision !83
  %28 = insertelement <4 x float> %27, float %v19, i32 1, !gla.precision !83
  %29 = insertelement <4 x float> %28, float %v19, i32 2, !gla.precision !83
  %30 = insertelement <4 x float> %29, float %v19, i32 3, !gla.precision !83
  %v20 = fmul <4 x float> %26, %30, !gla.precision !83
  store <4 x float> %v20, <4 x float>* %v
  %31 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %v21 = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %31, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %32 = sitofp <4 x i32> %v21 to <4 x float>, !gla.precision !83
  %33 = load <4 x float>* %v
  %v22 = fmul <4 x float> %33, %32, !gla.precision !83
  store <4 x float> %v22, <4 x float>* %v
  %34 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %v23 = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %34, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %35 = uitofp <4 x i32> %v23 to <4 x float>, !gla.precision !83
  %36 = load <4 x float>* %v
  %v24 = fmul <4 x float> %36, %35, !gla.precision !83
  store <4 x float> %v24, <4 x float>* %v
  %37 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %v25 = call <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32 4, i32 %37, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FCEB851E0000000, float undef), !gla.precision !83
  %38 = load <4 x float>* %v
  %v26 = fmul <4 x float> %38, %v25, !gla.precision !83
  store <4 x float> %v26, <4 x float>* %v
  %39 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %v27 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %39, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD0A3D700000000, float undef), !gla.precision !83
  %40 = sitofp <4 x i32> %v27 to <4 x float>, !gla.precision !83
  %41 = load <4 x float>* %v
  %v28 = fmul <4 x float> %41, %40, !gla.precision !83
  store <4 x float> %v28, <4 x float>* %v
  %42 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %v29 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %42, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD147AE20000000, float undef), !gla.precision !83
  %43 = uitofp <4 x i32> %v29 to <4 x float>, !gla.precision !83
  %44 = load <4 x float>* %v
  %v30 = fmul <4 x float> %44, %43, !gla.precision !83
  store <4 x float> %v30, <4 x float>* %v
  %45 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %v31 = call <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32 4, i32 %45, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %46 = load <4 x float>* %v
  %v32 = fmul <4 x float> %46, %v31, !gla.precision !83
  store <4 x float> %v32, <4 x float>* %v
  %47 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %v33 = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %47, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %48 = sitofp <4 x i32> %v33 to <4 x float>, !gla.precision !83
  %49 = load <4 x float>* %v
  %v34 = fmul <4 x float> %49, %48, !gla.precision !83
  store <4 x float> %v34, <4 x float>* %v
  %50 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %v35 = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %50, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %51 = uitofp <4 x i32> %v35 to <4 x float>, !gla.precision !83
  %52 = load <4 x float>* %v
  %v36 = fmul <4 x float> %52, %51, !gla.precision !83
  store <4 x float> %v36, <4 x float>* %v
  %53 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %v37 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %53, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %54 = load <4 x float>* %v
  %v38 = fmul <4 x float> %54, %v37, !gla.precision !83
  store <4 x float> %v38, <4 x float>* %v
  %55 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %v39 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %55, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 2, float undef), !gla.precision !83
  %56 = load <4 x float>* %v
  %v40 = fmul <4 x float> %56, %v39, !gla.precision !83
  store <4 x float> %v40, <4 x float>* %v
  %57 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %v41 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %57, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %58 = sitofp <4 x i32> %v41 to <4 x float>, !gla.precision !83
  %59 = load <4 x float>* %v
  %v42 = fmul <4 x float> %59, %58, !gla.precision !83
  store <4 x float> %v42, <4 x float>* %v
  %60 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %v43 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %60, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 1, float undef), !gla.precision !83
  %61 = sitofp <4 x i32> %v43 to <4 x float>, !gla.precision !83
  %62 = load <4 x float>* %v
  %v44 = fmul <4 x float> %62, %61, !gla.precision !83
  store <4 x float> %v44, <4 x float>* %v
  %63 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %v45 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %63, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %64 = uitofp <4 x i32> %v45 to <4 x float>, !gla.precision !83
  %65 = load <4 x float>* %v
  %v46 = fmul <4 x float> %65, %64, !gla.precision !83
  store <4 x float> %v46, <4 x float>* %v
  %66 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %v47 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %66, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 0, float undef), !gla.precision !83
  %67 = uitofp <4 x i32> %v47 to <4 x float>, !gla.precision !83
  %68 = load <4 x float>* %v
  %v48 = fmul <4 x float> %68, %67, !gla.precision !83
  store <4 x float> %v48, <4 x float>* %v
  %69 = load i32 addrspace(1)* @CA5, !gla.uniform !43
  %v49 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %69, i32 2136, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float 2.500000e+00), !gla.precision !83
  %70 = load <4 x float>* %v
  %v50 = fmul <4 x float> %70, %v49, !gla.precision !83
  store <4 x float> %v50, <4 x float>* %v
  %71 = load <4 x float>* %v
  ret <4 x float> %71

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"MSA("() #0 {
entry:
  %v7 = alloca <4 x float>
  %v = alloca <4 x float>
  %iv = alloca <3 x i32>
  store <3 x i32> zeroinitializer, <3 x i32>* %iv
  %0 = load i32 addrspace(1)* @samp2DMSA, !gla.uniform !61
  %iv1 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %0), !gla.precision !83
  %1 = load <3 x i32>* %iv
  %iv2 = add <3 x i32> %1, %iv1, !gla.precision !83
  store <3 x i32> %iv2, <3 x i32>* %iv
  %2 = load i32 addrspace(1)* @samp2DMSAi, !gla.uniform !64
  %iv3 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %2), !gla.precision !83
  %3 = load <3 x i32>* %iv
  %iv4 = add <3 x i32> %3, %iv3, !gla.precision !83
  store <3 x i32> %iv4, <3 x i32>* %iv
  %4 = load i32 addrspace(1)* @samp2DMSAu, !gla.uniform !67
  %iv5 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %4), !gla.precision !83
  %5 = load <3 x i32>* %iv
  %iv6 = add <3 x i32> %5, %iv5, !gla.precision !83
  store <3 x i32> %iv6, <3 x i32>* %iv
  %6 = load <3 x i32>* %iv
  %7 = sitofp <3 x i32> %6 to <3 x float>, !gla.precision !83
  %8 = load <4 x float>* %v7
  %9 = extractelement <3 x float> %7, i32 0, !gla.precision !83
  %10 = insertelement <4 x float> %8, float %9, i32 0, !gla.precision !83
  %11 = extractelement <3 x float> %7, i32 1, !gla.precision !83
  %12 = insertelement <4 x float> %10, float %11, i32 1, !gla.precision !83
  %13 = extractelement <3 x float> %7, i32 2, !gla.precision !83
  %14 = insertelement <4 x float> %12, float %13, i32 2, !gla.precision !83
  %v8 = insertelement <4 x float> %14, float 1.000000e+00, i32 3, !gla.precision !83
  store <4 x float> %v8, <4 x float>* %v
  %15 = load i32 addrspace(1)* @samp2DMSA, !gla.uniform !61
  %v9 = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32 6, i32 %15, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %16 = load <4 x float>* %v
  %v10 = fmul <4 x float> %16, %v9, !gla.precision !83
  store <4 x float> %v10, <4 x float>* %v
  %17 = load i32 addrspace(1)* @samp2DMSAi, !gla.uniform !64
  %v11 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %17, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %18 = sitofp <4 x i32> %v11 to <4 x float>, !gla.precision !83
  %19 = load <4 x float>* %v
  %v12 = fmul <4 x float> %19, %18, !gla.precision !83
  store <4 x float> %v12, <4 x float>* %v
  %20 = load i32 addrspace(1)* @samp2DMSAu, !gla.uniform !67
  %v13 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %20, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %21 = uitofp <4 x i32> %v13 to <4 x float>, !gla.precision !83
  %22 = load <4 x float>* %v
  %v14 = fmul <4 x float> %22, %21, !gla.precision !83
  store <4 x float> %v14, <4 x float>* %v
  %23 = load <4 x float>* %v
  ret <4 x float> %23

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc void @"goodImageAtom("() #0 {
entry:
  %datu = alloca i32
  %dati = alloca i32
  %datf = alloca float
  store float 0x3FFCCCCCC0000000, float* %datf
  store i32 4, i32* %dati
  store i32 7, i32* %datu
  %0 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %1 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %2 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %3 = extractelement <2 x i32> %2, i32 0, !gla.precision !83
  %4 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %0, <2 x i32> %1, i32 %3), !gla.precision !83
  %5 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %6 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %7 = load i32* %datu
  %8 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %5, <2 x i32> %6, i32 %7), !gla.precision !83
  %9 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %10 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %11 = load i32* %dati
  %12 = call i32 @llvm.gla.sImageAtomicMin.v2i32(i32 2, i32 %9, <2 x i32> %10, i32 %11), !gla.precision !83
  %13 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %14 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %15 = load i32* %datu
  %16 = call i32 @llvm.gla.uImageAtomicMin.v2i32(i32 2, i32 %13, <2 x i32> %14, i32 %15), !gla.precision !83
  %17 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %18 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %19 = load i32* %dati
  %20 = call i32 @llvm.gla.sImageAtomicMax.v2i32(i32 2, i32 %17, <2 x i32> %18, i32 %19), !gla.precision !83
  %21 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %22 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %23 = load i32* %datu
  %24 = call i32 @llvm.gla.uImageAtomicMax.v2i32(i32 2, i32 %21, <2 x i32> %22, i32 %23), !gla.precision !83
  %25 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %26 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %27 = load i32* %dati
  %28 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %25, <2 x i32> %26, i32 %27), !gla.precision !83
  %29 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %30 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %31 = load i32* %datu
  %32 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %29, <2 x i32> %30, i32 %31), !gla.precision !83
  %33 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %34 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %35 = load i32* %dati
  %36 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %33, <2 x i32> %34, i32 %35), !gla.precision !83
  %37 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %38 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %39 = load i32* %datu
  %40 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %37, <2 x i32> %38, i32 %39), !gla.precision !83
  %41 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %42 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %43 = load i32* %dati
  %44 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %41, <2 x i32> %42, i32 %43), !gla.precision !83
  %45 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %46 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %47 = load i32* %datu
  %48 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %45, <2 x i32> %46, i32 %47), !gla.precision !83
  %49 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %50 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %51 = load i32* %dati
  %52 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %49, <2 x i32> %50, i32 %51), !gla.precision !83
  %53 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %54 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %55 = load i32* %datu
  %56 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %53, <2 x i32> %54, i32 %55), !gla.precision !83
  %57 = load i32 addrspace(1)* @im2Df, !gla.uniform !77
  %58 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %59 = load float* %datf
  %60 = call float @llvm.gla.fImageAtomicExchange.v2i32(i32 2, i32 %57, <2 x i32> %58, float %59), !gla.precision !83
  %61 = load i32 addrspace(1)* @im2Di, !gla.uniform !70
  %62 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %63 = load i32* %dati
  %64 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %61, <2 x i32> %62, i32 3, i32 %63), !gla.precision !83
  %65 = load i32 addrspace(1)* @im2Du, !gla.uniform !74
  %66 = load <2 x i32> addrspace(2)* @P, !gla.uniform !73
  %67 = load i32* %datu
  %68 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %65, <2 x i32> %66, i32 5, i32 %67), !gla.precision !83
  ret void
}

; Function Attrs: nounwind readnone
declare <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float>, <2 x float>, <2 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>, <2 x i32>, <2 x i32>, <2 x i32>) #1

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryTextureSizeNoLod.i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryImageSize.i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32, i32, i32) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryImageSize.v3i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32, i32, i32, <4 x float>) #1

; Function Attrs: nounwind readnone
declare float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32, i32, i32, <4 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32, i32, i32, <4 x float>, i32, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32, i32, i32, <4 x float>, i32, float) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAdd.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAnd.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicOr.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicXor.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.iImageAtomicExchange.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare float @llvm.gla.fImageAtomicExchange.v2i32(i32, i32, <2 x i32>, float) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32, i32, <2 x i32>, i32, i32) #2

attributes #0 = { alwaysinline }
attributes #1 = { nounwind readnone }
attributes #2 = { nounwind }

!gla.entrypoint = !{!0}
!gla.inputs = !{!1, !3, !5, !7, !9}
!gla.uniforms = !{!11, !14, !16, !19, !22, !25, !28, !31, !34, !37, !40, !43, !46, !49, !52, !55, !58, !61, !64, !67, !70, !73, !74, !77}
!gla.outputs = !{!80}
!gla.noStaticUse = !{!7, !9}

!0 = !{!"main", i32 15}
!1 = !{!"inf", i32 1, <2 x float>* @inf_typeProxy, !2, !""}
!2 = !{i32 0, i32 3, i32 1024, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!3 = !{!"ing", i32 1, <2 x float>* @ing_typeProxy, !4, !""}
!4 = !{i32 0, i32 3, i32 1025, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!5 = !{!"inch", i32 1, <2 x float>* @inch_typeProxy, !6, !""}
!6 = !{i32 0, i32 3, i32 1026, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!7 = !{!"gl_VertexID", i32 2, i32* @gl_VertexID_typeProxy, !8, !""}
!8 = !{i32 0, i32 3, i32 1028, null, i32 0, i32 7, i32 -1, i32 0, i32 -1}
!9 = !{!"gl_InstanceID", i32 3, i32* @gl_InstanceID_typeProxy, !10, !""}
!10 = !{i32 0, i32 3, i32 1029, null, i32 0, i32 8, i32 -1, i32 0, i32 -1}
!11 = !{!"iArray", i32 12, [5 x i32]* @iArray_typeProxy, !12, !""}
!12 = !{i32 5, i32 1, i32 1024, !13, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!13 = !{i32 1, [5 x i32]* @iArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!14 = !{!"index", i32 12, i32* @index_typeProxy, !15, !""}
!15 = !{i32 0, i32 3, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!16 = !{!"sArray", i32 12, [4 x i32]* @sArray_typeProxy, !17, !""}
!17 = !{i32 5, i32 1, i32 1024, !18, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!18 = !{i32 0, [4 x i32]* @sArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!19 = !{!"ubInst", i32 13, [4 x %ubName]* @ubInst_typeProxy, !20, !"ubName", !21}
!20 = !{i32 6, i32 0, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!21 = !{!"p", i32 12, <2 x float>* @p_typeProxy, !15, !""}
!22 = !{!"bufSamp1", i32 12, i32* @bufSamp1_typeProxy, !23, !""}
!23 = !{i32 5, i32 3, i32 1024, !24, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!24 = !{i32 0, i32* @bufSamp1_typeProxy, i32 5, i1 false, i1 false, i32 0}
!25 = !{!"bufSamp2", i32 12, i32* @bufSamp2_typeProxy, !26, !""}
!26 = !{i32 5, i32 3, i32 1024, !27, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!27 = !{i32 0, i32* @bufSamp2_typeProxy, i32 5, i1 false, i1 false, i32 1}
!28 = !{!"bufSamp3", i32 12, i32* @bufSamp3_typeProxy, !29, !""}
!29 = !{i32 5, i32 3, i32 1024, !30, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!30 = !{i32 0, i32* @bufSamp3_typeProxy, i32 5, i1 false, i1 false, i32 2}
!31 = !{!"bufSamp4", i32 12, i32* @bufSamp4_typeProxy, !32, !""}
!32 = !{i32 5, i32 3, i32 1024, !33, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!33 = !{i32 1, i32* @bufSamp4_typeProxy, i32 5, i1 false, i1 false, i32 0}
!34 = !{!"bufSamp5", i32 12, i32* @bufSamp5_typeProxy, !35, !""}
!35 = !{i32 5, i32 3, i32 1024, !36, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!36 = !{i32 1, i32* @bufSamp5_typeProxy, i32 5, i1 false, i1 false, i32 1}
!37 = !{!"bufSamp6", i32 12, i32* @bufSamp6_typeProxy, !38, !""}
!38 = !{i32 5, i32 3, i32 1024, !39, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!39 = !{i32 1, i32* @bufSamp6_typeProxy, i32 5, i1 false, i1 false, i32 2}
!40 = !{!"CA4", i32 12, i32* @CA4_typeProxy, !41, !""}
!41 = !{i32 5, i32 3, i32 1024, !42, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!42 = !{i32 0, i32* @CA4_typeProxy, i32 3, i1 true, i1 false, i32 0}
!43 = !{!"CA5", i32 12, i32* @CA5_typeProxy, !44, !""}
!44 = !{i32 5, i32 3, i32 1024, !45, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!45 = !{i32 0, i32* @CA5_typeProxy, i32 3, i1 true, i1 true, i32 0}
!46 = !{!"CA6", i32 12, i32* @CA6_typeProxy, !47, !""}
!47 = !{i32 5, i32 3, i32 1024, !48, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!48 = !{i32 0, i32* @CA6_typeProxy, i32 3, i1 true, i1 false, i32 1}
!49 = !{!"CA7", i32 12, i32* @CA7_typeProxy, !50, !""}
!50 = !{i32 5, i32 3, i32 1024, !51, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!51 = !{i32 0, i32* @CA7_typeProxy, i32 3, i1 true, i1 false, i32 2}
!52 = !{!"CA1", i32 12, i32* @CA1_typeProxy, !53, !""}
!53 = !{i32 5, i32 3, i32 1024, !54, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!54 = !{i32 1, i32* @CA1_typeProxy, i32 3, i1 true, i1 false, i32 0}
!55 = !{!"CA2", i32 12, i32* @CA2_typeProxy, !56, !""}
!56 = !{i32 5, i32 3, i32 1024, !57, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!57 = !{i32 1, i32* @CA2_typeProxy, i32 3, i1 true, i1 false, i32 1}
!58 = !{!"CA3", i32 12, i32* @CA3_typeProxy, !59, !""}
!59 = !{i32 5, i32 3, i32 1024, !60, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!60 = !{i32 1, i32* @CA3_typeProxy, i32 3, i1 true, i1 false, i32 2}
!61 = !{!"samp2DMSA", i32 12, i32* @samp2DMSA_typeProxy, !62, !""}
!62 = !{i32 5, i32 3, i32 1024, !63, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!63 = !{i32 0, i32* @samp2DMSA_typeProxy, i32 6, i1 true, i1 false, i32 0}
!64 = !{!"samp2DMSAi", i32 12, i32* @samp2DMSAi_typeProxy, !65, !""}
!65 = !{i32 5, i32 3, i32 1024, !66, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!66 = !{i32 0, i32* @samp2DMSAi_typeProxy, i32 6, i1 true, i1 false, i32 1}
!67 = !{!"samp2DMSAu", i32 12, i32* @samp2DMSAu_typeProxy, !68, !""}
!68 = !{i32 5, i32 3, i32 1024, !69, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!69 = !{i32 0, i32* @samp2DMSAu_typeProxy, i32 6, i1 true, i1 false, i32 2}
!70 = !{!"im2Di", i32 12, i32* @im2Di_typeProxy, !71, !""}
!71 = !{i32 5, i32 3, i32 1024, !72, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!72 = !{i32 25, i32* @im2Di_typeProxy, i32 1, i1 false, i1 false, i32 1}
!73 = !{!"P", i32 12, <2 x i32>* @P_typeProxy, !15, !""}
!74 = !{!"im2Du", i32 12, i32* @im2Du_typeProxy, !75, !""}
!75 = !{i32 5, i32 3, i32 1024, !76, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!76 = !{i32 34, i32* @im2Du_typeProxy, i32 1, i1 false, i1 false, i32 2}
!77 = !{!"im2Df", i32 12, i32* @im2Df_typeProxy, !78, !""}
!78 = !{i32 5, i32 3, i32 1024, !79, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!79 = !{i32 4, i32* @im2Df_typeProxy, i32 1, i1 false, i1 false, i32 0}
!80 = !{!"outInst", i32 16, %outName* @outInst_typeProxy, !81, !"outName", !82}
!81 = !{i32 0, i32 0, i32 1027, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!82 = !{!"color", i32 7, <4 x float>* @color_typeProxy, !2, !""}
!83 = !{i32 3}


Bottom IR:
; ModuleID = 'Glslang'
target datalayout = "e-p:32:32"

%ubName = type { <2 x float> }
%outName = type { <4 x float> }

@inf = global <2 x float> zeroinitializer
@ing = global <2 x float> zeroinitializer
@inch = global <2 x float> zeroinitializer
@index = external addrspace(2) constant i32
@sArray = external addrspace(1) constant [4 x i32]
@ubInst = external addrspace(2) constant [4 x %ubName]
@outInst = global %outName zeroinitializer
@bufSamp1 = external addrspace(1) constant i32
@bufSamp2 = external addrspace(1) constant i32
@bufSamp3 = external addrspace(1) constant i32
@bufSamp4 = external addrspace(1) constant i32
@bufSamp5 = external addrspace(1) constant i32
@bufSamp6 = external addrspace(1) constant i32
@CA4 = external addrspace(1) constant i32
@CA5 = external addrspace(1) constant i32
@CA6 = external addrspace(1) constant i32
@CA7 = external addrspace(1) constant i32
@CA1 = external addrspace(1) constant i32
@CA2 = external addrspace(1) constant i32
@CA3 = external addrspace(1) constant i32
@samp2DMSA = external addrspace(1) constant i32
@samp2DMSAi = external addrspace(1) constant i32
@samp2DMSAu = external addrspace(1) constant i32
@im2Di = external addrspace(1) constant i32
@P = external addrspace(2) constant <2 x i32>
@im2Du = external addrspace(1) constant i32
@im2Df = external addrspace(1) constant i32
@gl_VertexID = global i32 0
@gl_InstanceID = global i32 0

define fastcc void @main() {
entry:
  %0 = load <2 x float>* @inf
  %1 = load <2 x float>* @ing
  %2 = load <2 x float>* @inch
  %p2 = call <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float> %0, <2 x float> %1, <2 x float> %2), !gla.precision !83
  %3 = load i32 addrspace(2)* @index, !gla.uniform !14
  %4 = getelementptr [4 x i32] addrspace(1)* @sArray, i32 0, i32 %3
  %5 = load i32 addrspace(1)* %4, !gla.uniform !16
  %6 = getelementptr [4 x %ubName] addrspace(2)* @ubInst, i32 0, i32 %3, i32 0
  %7 = load <2 x float> addrspace(2)* %6, !gla.uniform !19
  %8 = fptosi <2 x float> %0 to <2 x i32>, !gla.precision !83
  %color3 = call <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32 2, i32 %5, i32 320, <2 x float> %7, i32 undef, float undef, <2 x i32> %8), !gla.precision !83
  %color4 = fadd <4 x float> %color3, zeroinitializer, !gla.precision !83
  %color5 = call <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32 2, i32 %5, i32 8512, <2 x float> %p2, i32 undef, float undef, <2 x i32> <i32 1, i32 1>, <2 x i32> <i32 2, i32 2>, <2 x i32> <i32 3, i32 3>, <2 x i32> <i32 4, i32 4>), !gla.precision !83
  %color6 = fadd <4 x float> %color4, %color5, !gla.precision !83
  %gla_constGEP = getelementptr %outName* @outInst, i32 0, i32 0
  store <4 x float> %color6, <4 x float>* %gla_constGEP
  %9 = load i32 addrspace(1)* @bufSamp1, !gla.uniform !22
  %s12.i = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %9), !gla.precision !83
  %10 = sitofp i32 %s12.i to float, !gla.precision !83
  %11 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %10, <4 x i32> zeroinitializer)
  %12 = load i32 addrspace(1)* @bufSamp2, !gla.uniform !25
  %s16.i = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %12), !gla.precision !83
  %13 = sitofp i32 %s16.i to float, !gla.precision !83
  %14 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %13, <4 x i32> zeroinitializer)
  %v8.i = fmul <4 x float> %11, %14, !gla.precision !83
  %15 = load i32 addrspace(1)* @bufSamp3, !gla.uniform !28
  %s110.i = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %15), !gla.precision !83
  %16 = sitofp i32 %s110.i to float, !gla.precision !83
  %17 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %16, <4 x i32> zeroinitializer)
  %v12.i = fmul <4 x float> %v8.i, %17, !gla.precision !83
  %18 = load i32 addrspace(1)* @bufSamp4, !gla.uniform !31
  %s114.i = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %18), !gla.precision !83
  %19 = sitofp i32 %s114.i to float, !gla.precision !83
  %20 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %19, <4 x i32> zeroinitializer)
  %v16.i = fmul <4 x float> %v12.i, %20, !gla.precision !83
  %21 = load i32 addrspace(1)* @bufSamp5, !gla.uniform !34
  %s118.i = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %21), !gla.precision !83
  %22 = sitofp i32 %s118.i to float, !gla.precision !83
  %23 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %22, <4 x i32> zeroinitializer)
  %v20.i = fmul <4 x float> %v16.i, %23, !gla.precision !83
  %24 = load i32 addrspace(1)* @bufSamp6, !gla.uniform !37
  %s122.i = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %24), !gla.precision !83
  %25 = sitofp i32 %s122.i to float, !gla.precision !83
  %26 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %25, <4 x i32> zeroinitializer)
  %v24.i = fmul <4 x float> %v20.i, %26, !gla.precision !83
  %v25.i = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32 0, i32 %9, i32 32, i32 %s122.i, i32 undef, float undef, i32 undef), !gla.precision !83
  %v26.i = fmul <4 x float> %v25.i, %v24.i, !gla.precision !83
  %v27.i = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %12, i32 32, i32 %s122.i, i32 undef, float undef, i32 undef), !gla.precision !83
  %27 = sitofp <4 x i32> %v27.i to <4 x float>, !gla.precision !83
  %v28.i = fmul <4 x float> %27, %v26.i, !gla.precision !83
  %v29.i = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %15, i32 32, i32 %s122.i, i32 undef, float undef, i32 undef), !gla.precision !83
  %28 = uitofp <4 x i32> %v29.i to <4 x float>, !gla.precision !83
  %v30.i = fmul <4 x float> %28, %v28.i, !gla.precision !83
  %29 = fadd <4 x float> %color6, %v30.i, !gla.precision !83
  %gla_constGEP23 = getelementptr %outName* @outInst, i32 0, i32 0
  store <4 x float> %29, <4 x float>* %gla_constGEP23
  %30 = load i32 addrspace(1)* @CA4, !gla.uniform !40
  %iv1.i9 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %30, i32 1), !gla.precision !83
  %31 = load i32 addrspace(1)* @CA5, !gla.uniform !43
  %iv3.i10 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %31, i32 1), !gla.precision !83
  %iv4.i11 = add <3 x i32> %iv1.i9, %iv3.i10, !gla.precision !83
  %32 = load i32 addrspace(1)* @CA6, !gla.uniform !46
  %iv5.i12 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %32, i32 1), !gla.precision !83
  %iv6.i13 = add <3 x i32> %iv4.i11, %iv5.i12, !gla.precision !83
  %33 = load i32 addrspace(1)* @CA7, !gla.uniform !49
  %iv7.i = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %33, i32 1), !gla.precision !83
  %iv8.i = add <3 x i32> %iv6.i13, %iv7.i, !gla.precision !83
  %34 = load i32 addrspace(1)* @CA1, !gla.uniform !52
  %iv9.i = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %34), !gla.precision !83
  %iv10.i = add <3 x i32> %iv8.i, %iv9.i, !gla.precision !83
  %35 = load i32 addrspace(1)* @CA2, !gla.uniform !55
  %iv11.i = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %35), !gla.precision !83
  %iv12.i = add <3 x i32> %iv10.i, %iv11.i, !gla.precision !83
  %36 = load i32 addrspace(1)* @CA3, !gla.uniform !58
  %iv13.i = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %36), !gla.precision !83
  %iv14.i = add <3 x i32> %iv12.i, %iv13.i, !gla.precision !83
  %37 = sitofp <3 x i32> %iv14.i to <3 x float>, !gla.precision !83
  %38 = call <4 x float> @llvm.gla.fMultiInsert.v4f32.v4f32.v3f32.v3f32.v3f32.f32(<4 x float> undef, i32 15, <3 x float> %37, i32 0, <3 x float> %37, i32 1, <3 x float> %37, i32 2, float 1.000000e+00, i32 0)
  %v17.i = call <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32 4, i32 %30, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %v18.i = fmul <4 x float> %v17.i, %38, !gla.precision !83
  %v19.i = call float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32 4, i32 %31, i32 154, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 3.000000e+00, float undef), !gla.precision !83
  %39 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %v19.i, <4 x i32> zeroinitializer)
  %v20.i15 = fmul <4 x float> %39, %v18.i, !gla.precision !83
  %v21.i = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %32, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %40 = sitofp <4 x i32> %v21.i to <4 x float>, !gla.precision !83
  %v22.i = fmul <4 x float> %40, %v20.i15, !gla.precision !83
  %v23.i = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %33, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !83
  %41 = uitofp <4 x i32> %v23.i to <4 x float>, !gla.precision !83
  %v24.i16 = fmul <4 x float> %41, %v22.i, !gla.precision !83
  %v25.i17 = call <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32 4, i32 %30, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FCEB851E0000000, float undef), !gla.precision !83
  %v26.i18 = fmul <4 x float> %v25.i17, %v24.i16, !gla.precision !83
  %v27.i19 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %32, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD0A3D700000000, float undef), !gla.precision !83
  %42 = sitofp <4 x i32> %v27.i19 to <4 x float>, !gla.precision !83
  %v28.i20 = fmul <4 x float> %42, %v26.i18, !gla.precision !83
  %v29.i21 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %33, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD147AE20000000, float undef), !gla.precision !83
  %43 = uitofp <4 x i32> %v29.i21 to <4 x float>, !gla.precision !83
  %v30.i22 = fmul <4 x float> %43, %v28.i20, !gla.precision !83
  %v31.i = call <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32 4, i32 %30, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %v32.i = fmul <4 x float> %v31.i, %v30.i22, !gla.precision !83
  %v33.i = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %32, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %44 = sitofp <4 x i32> %v33.i to <4 x float>, !gla.precision !83
  %v34.i = fmul <4 x float> %44, %v32.i, !gla.precision !83
  %v35.i = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %33, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !83
  %45 = uitofp <4 x i32> %v35.i to <4 x float>, !gla.precision !83
  %v36.i = fmul <4 x float> %45, %v34.i, !gla.precision !83
  %v37.i = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %30, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %v38.i = fmul <4 x float> %v37.i, %v36.i, !gla.precision !83
  %v39.i = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %30, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 2, float undef), !gla.precision !83
  %v40.i = fmul <4 x float> %v39.i, %v38.i, !gla.precision !83
  %v41.i = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %32, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %46 = sitofp <4 x i32> %v41.i to <4 x float>, !gla.precision !83
  %v42.i = fmul <4 x float> %46, %v40.i, !gla.precision !83
  %v43.i = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %32, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 1, float undef), !gla.precision !83
  %47 = sitofp <4 x i32> %v43.i to <4 x float>, !gla.precision !83
  %v44.i = fmul <4 x float> %47, %v42.i, !gla.precision !83
  %v45.i = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %33, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !83
  %48 = uitofp <4 x i32> %v45.i to <4 x float>, !gla.precision !83
  %v46.i = fmul <4 x float> %48, %v44.i, !gla.precision !83
  %v47.i = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %33, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 0, float undef), !gla.precision !83
  %49 = uitofp <4 x i32> %v47.i to <4 x float>, !gla.precision !83
  %v48.i = fmul <4 x float> %49, %v46.i, !gla.precision !83
  %v49.i = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %31, i32 2136, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float 2.500000e+00), !gla.precision !83
  %v50.i = fmul <4 x float> %v49.i, %v48.i, !gla.precision !83
  %50 = fadd <4 x float> %29, %v50.i, !gla.precision !83
  %gla_constGEP24 = getelementptr %outName* @outInst, i32 0, i32 0
  store <4 x float> %50, <4 x float>* %gla_constGEP24
  %51 = load i32 addrspace(1)* @samp2DMSA, !gla.uniform !61
  %iv1.i = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %51), !gla.precision !83
  %52 = load i32 addrspace(1)* @samp2DMSAi, !gla.uniform !64
  %iv3.i = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %52), !gla.precision !83
  %iv4.i = add <3 x i32> %iv1.i, %iv3.i, !gla.precision !83
  %53 = load i32 addrspace(1)* @samp2DMSAu, !gla.uniform !67
  %iv5.i = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %53), !gla.precision !83
  %iv6.i = add <3 x i32> %iv4.i, %iv5.i, !gla.precision !83
  %54 = sitofp <3 x i32> %iv6.i to <3 x float>, !gla.precision !83
  %55 = call <4 x float> @llvm.gla.fMultiInsert.v4f32.v4f32.v3f32.v3f32.v3f32.f32(<4 x float> undef, i32 15, <3 x float> %54, i32 0, <3 x float> %54, i32 1, <3 x float> %54, i32 2, float 1.000000e+00, i32 0)
  %v9.i = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32 6, i32 %51, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %v10.i = fmul <4 x float> %v9.i, %55, !gla.precision !83
  %v11.i = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %52, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %56 = sitofp <4 x i32> %v11.i to <4 x float>, !gla.precision !83
  %v12.i8 = fmul <4 x float> %56, %v10.i, !gla.precision !83
  %v13.i = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %53, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !83
  %57 = uitofp <4 x i32> %v13.i to <4 x float>, !gla.precision !83
  %v14.i = fmul <4 x float> %57, %v12.i8, !gla.precision !83
  %58 = fadd <4 x float> %50, %v14.i, !gla.precision !83
  %gla_constGEP25 = getelementptr %outName* @outInst, i32 0, i32 0
  store <4 x float> %58, <4 x float>* %gla_constGEP25
  %59 = load i32 addrspace(1)* @im2Di
  %60 = load <2 x i32> addrspace(2)* @P
  %61 = extractelement <2 x i32> %60, i32 0, !gla.precision !83
  %62 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 %61), !gla.precision !83
  %63 = load i32 addrspace(1)* @im2Du
  %64 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %65 = call i32 @llvm.gla.sImageAtomicMin.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %66 = call i32 @llvm.gla.uImageAtomicMin.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %67 = call i32 @llvm.gla.sImageAtomicMax.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %68 = call i32 @llvm.gla.uImageAtomicMax.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %69 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %70 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %71 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %72 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %73 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %74 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %75 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 4), !gla.precision !83
  %76 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 7), !gla.precision !83
  %77 = load i32 addrspace(1)* @im2Df, !gla.uniform !77
  %78 = call float @llvm.gla.fImageAtomicExchange.v2i32(i32 2, i32 %77, <2 x i32> %60, float 0x3FFCCCCCC0000000), !gla.precision !83
  %79 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %59, <2 x i32> %60, i32 3, i32 4), !gla.precision !83
  %80 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %63, <2 x i32> %60, i32 5, i32 7), !gla.precision !83
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %entry
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float>, <2 x float>, <2 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>, <2 x i32>, <2 x i32>, <2 x i32>) #0

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryTextureSizeNoLod.i32(i32, i32) #0

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryImageSize.i32(i32, i32) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #0

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32, i32, i32) #0

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryImageSize.v3i32(i32, i32) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32, i32, i32, <4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32, i32, i32, <4 x float>, float, float) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32, i32, i32, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32, i32, i32, <4 x float>, float, float) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32, i32, i32, <4 x float>, float, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32, i32, i32, <4 x float>, i32, float) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32, i32, i32, <4 x float>, i32, float) #0

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32, i32) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #0

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #0

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAdd.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAnd.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicOr.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicXor.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.iImageAtomicExchange.v2i32(i32, i32, <2 x i32>, i32) #1

; Function Attrs: nounwind
declare float @llvm.gla.fImageAtomicExchange.v2i32(i32, i32, <2 x i32>, float) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32, i32, <2 x i32>, i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMultiInsert.v4f32.v4f32.v3f32.v3f32.v3f32.f32(<4 x float>, i32, <3 x float>, i32, <3 x float>, i32, <3 x float>, i32, float, i32) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float, <4 x i32>) #0

attributes #0 = { nounwind readnone }
attributes #1 = { nounwind }

!gla.entrypoint = !{!0}
!gla.inputs = !{!1, !3, !5, !7, !9}
!gla.uniforms = !{!11, !14, !16, !19, !22, !25, !28, !31, !34, !37, !40, !43, !46, !49, !52, !55, !58, !61, !64, !67, !70, !73, !74, !77}
!gla.outputs = !{!80}
!gla.noStaticUse = !{!7, !9}

!0 = !{!"main", i32 15}
!1 = !{!"inf", i32 1, <2 x float>* @inf_typeProxy, !2, !""}
!2 = !{i32 0, i32 3, i32 1024, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!3 = !{!"ing", i32 1, <2 x float>* @ing_typeProxy, !4, !""}
!4 = !{i32 0, i32 3, i32 1025, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!5 = !{!"inch", i32 1, <2 x float>* @inch_typeProxy, !6, !""}
!6 = !{i32 0, i32 3, i32 1026, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!7 = !{!"gl_VertexID", i32 2, i32* @gl_VertexID_typeProxy, !8, !""}
!8 = !{i32 0, i32 3, i32 1028, null, i32 0, i32 7, i32 -1, i32 0, i32 -1}
!9 = !{!"gl_InstanceID", i32 3, i32* @gl_InstanceID_typeProxy, !10, !""}
!10 = !{i32 0, i32 3, i32 1029, null, i32 0, i32 8, i32 -1, i32 0, i32 -1}
!11 = !{!"iArray", i32 12, [5 x i32]* @iArray_typeProxy, !12, !""}
!12 = !{i32 5, i32 1, i32 1024, !13, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!13 = !{i32 1, [5 x i32]* @iArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!14 = !{!"index", i32 12, i32* @index_typeProxy, !15, !""}
!15 = !{i32 0, i32 3, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!16 = !{!"sArray", i32 12, [4 x i32]* @sArray_typeProxy, !17, !""}
!17 = !{i32 5, i32 1, i32 1024, !18, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!18 = !{i32 0, [4 x i32]* @sArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!19 = !{!"ubInst", i32 13, [4 x %ubName]* @ubInst_typeProxy, !20, !"ubName", !21}
!20 = !{i32 6, i32 0, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!21 = !{!"p", i32 12, <2 x float>* @p_typeProxy, !15, !""}
!22 = !{!"bufSamp1", i32 12, i32* @bufSamp1_typeProxy, !23, !""}
!23 = !{i32 5, i32 3, i32 1024, !24, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!24 = !{i32 0, i32* @bufSamp1_typeProxy, i32 5, i1 false, i1 false, i32 0}
!25 = !{!"bufSamp2", i32 12, i32* @bufSamp2_typeProxy, !26, !""}
!26 = !{i32 5, i32 3, i32 1024, !27, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!27 = !{i32 0, i32* @bufSamp2_typeProxy, i32 5, i1 false, i1 false, i32 1}
!28 = !{!"bufSamp3", i32 12, i32* @bufSamp3_typeProxy, !29, !""}
!29 = !{i32 5, i32 3, i32 1024, !30, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!30 = !{i32 0, i32* @bufSamp3_typeProxy, i32 5, i1 false, i1 false, i32 2}
!31 = !{!"bufSamp4", i32 12, i32* @bufSamp4_typeProxy, !32, !""}
!32 = !{i32 5, i32 3, i32 1024, !33, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!33 = !{i32 1, i32* @bufSamp4_typeProxy, i32 5, i1 false, i1 false, i32 0}
!34 = !{!"bufSamp5", i32 12, i32* @bufSamp5_typeProxy, !35, !""}
!35 = !{i32 5, i32 3, i32 1024, !36, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!36 = !{i32 1, i32* @bufSamp5_typeProxy, i32 5, i1 false, i1 false, i32 1}
!37 = !{!"bufSamp6", i32 12, i32* @bufSamp6_typeProxy, !38, !""}
!38 = !{i32 5, i32 3, i32 1024, !39, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!39 = !{i32 1, i32* @bufSamp6_typeProxy, i32 5, i1 false, i1 false, i32 2}
!40 = !{!"CA4", i32 12, i32* @CA4_typeProxy, !41, !""}
!41 = !{i32 5, i32 3, i32 1024, !42, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!42 = !{i32 0, i32* @CA4_typeProxy, i32 3, i1 true, i1 false, i32 0}
!43 = !{!"CA5", i32 12, i32* @CA5_typeProxy, !44, !""}
!44 = !{i32 5, i32 3, i32 1024, !45, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!45 = !{i32 0, i32* @CA5_typeProxy, i32 3, i1 true, i1 true, i32 0}
!46 = !{!"CA6", i32 12, i32* @CA6_typeProxy, !47, !""}
!47 = !{i32 5, i32 3, i32 1024, !48, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!48 = !{i32 0, i32* @CA6_typeProxy, i32 3, i1 true, i1 false, i32 1}
!49 = !{!"CA7", i32 12, i32* @CA7_typeProxy, !50, !""}
!50 = !{i32 5, i32 3, i32 1024, !51, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!51 = !{i32 0, i32* @CA7_typeProxy, i32 3, i1 true, i1 false, i32 2}
!52 = !{!"CA1", i32 12, i32* @CA1_typeProxy, !53, !""}
!53 = !{i32 5, i32 3, i32 1024, !54, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!54 = !{i32 1, i32* @CA1_typeProxy, i32 3, i1 true, i1 false, i32 0}
!55 = !{!"CA2", i32 12, i32* @CA2_typeProxy, !56, !""}
!56 = !{i32 5, i32 3, i32 1024, !57, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!57 = !{i32 1, i32* @CA2_typeProxy, i32 3, i1 true, i1 false, i32 1}
!58 = !{!"CA3", i32 12, i32* @CA3_typeProxy, !59, !""}
!59 = !{i32 5, i32 3, i32 1024, !60, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!60 = !{i32 1, i32* @CA3_typeProxy, i32 3, i1 true, i1 false, i32 2}
!61 = !{!"samp2DMSA", i32 12, i32* @samp2DMSA_typeProxy, !62, !""}
!62 = !{i32 5, i32 3, i32 1024, !63, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!63 = !{i32 0, i32* @samp2DMSA_typeProxy, i32 6, i1 true, i1 false, i32 0}
!64 = !{!"samp2DMSAi", i32 12, i32* @samp2DMSAi_typeProxy, !65, !""}
!65 = !{i32 5, i32 3, i32 1024, !66, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!66 = !{i32 0, i32* @samp2DMSAi_typeProxy, i32 6, i1 true, i1 false, i32 1}
!67 = !{!"samp2DMSAu", i32 12, i32* @samp2DMSAu_typeProxy, !68, !""}
!68 = !{i32 5, i32 3, i32 1024, !69, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!69 = !{i32 0, i32* @samp2DMSAu_typeProxy, i32 6, i1 true, i1 false, i32 2}
!70 = !{!"im2Di", i32 12, i32* @im2Di_typeProxy, !71, !""}
!71 = !{i32 5, i32 3, i32 1024, !72, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!72 = !{i32 25, i32* @im2Di_typeProxy, i32 1, i1 false, i1 false, i32 1}
!73 = !{!"P", i32 12, <2 x i32>* @P_typeProxy, !15, !""}
!74 = !{!"im2Du", i32 12, i32* @im2Du_typeProxy, !75, !""}
!75 = !{i32 5, i32 3, i32 1024, !76, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!76 = !{i32 34, i32* @im2Du_typeProxy, i32 1, i1 false, i1 false, i32 2}
!77 = !{!"im2Df", i32 12, i32* @im2Df_typeProxy, !78, !""}
!78 = !{i32 5, i32 3, i32 1024, !79, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!79 = !{i32 4, i32* @im2Df_typeProxy, i32 1, i1 false, i1 false, i32 0}
!80 = !{!"outInst", i32 16, %outName* @outInst_typeProxy, !81, !"outName", !82}
!81 = !{i32 0, i32 0, i32 1027, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!82 = !{!"color", i32 7, <4 x float>* @color_typeProxy, !2, !""}
!83 = !{i32 3}
#version 310 es
// LunarGOO output
#extension GL_ANDROID_extension_pack_es31a : enable
#extension GL_EXT_geometry_shader : enable
#extension GL_EXT_gpu_shader5 : enable
#extension GL_EXT_primitive_bounding_box : enable
#extension GL_EXT_shader_io_blocks : enable
#extension GL_EXT_tessellation_shader : enable
#extension GL_EXT_texture_buffer : enable
#extension GL_EXT_texture_cube_map_array : enable
#extension GL_KHR_blend_equation_advanced : enable
#extension GL_OES_sample_variables : enable
#extension GL_OES_shader_image_atomic : enable
#extension GL_OES_shader_multisample_interpolation : enable
#extension GL_OES_texture_storage_multisample_2d_array : enable
 writeonly uniform lowp image2D iArray[5];
uniform highp int index;
uniform lowp sampler2D sArray[4];
uniform ubName {
	highp vec2 p;
} ubInst[4];
uniform highp samplerBuffer bufSamp1;
uniform highp isamplerBuffer bufSamp2;
uniform highp usamplerBuffer bufSamp3;
 writeonly uniform highp imageBuffer bufSamp4;
 writeonly uniform highp iimageBuffer bufSamp5;
 writeonly uniform highp uimageBuffer bufSamp6;
uniform highp samplerCubeArray CA4;
uniform highp samplerCubeArrayShadow CA5;
uniform highp isamplerCubeArray CA6;
uniform highp usamplerCubeArray CA7;
 writeonly uniform highp imageCubeArray CA1;
 writeonly uniform highp iimageCubeArray CA2;
 writeonly uniform highp uimageCubeArray CA3;
uniform highp sampler2DMSArray samp2DMSA;
uniform highp isampler2DMSArray samp2DMSAi;
uniform highp usampler2DMSArray samp2DMSAu;
uniform layout(r32i) highp iimage2D im2Di;
uniform highp ivec2 P;
uniform layout(r32ui) highp uimage2D im2Du;
uniform layout(r32f) highp image2D im2Df;
in highp vec2 inf;
in highp vec2 ing;
in highp vec2 inch;
out outName {
	highp vec4 color;
} outInst;
const vec4 C_vec4p0d0p = vec4(0.0);
const ivec2[4] offsets_1 = ivec2[4](ivec2(1), ivec2(2), ivec2(3), ivec2(4));
const int C_1 = 1;
const float C_1d0 = 1.0;
const vec4 C_vec4p0d5p = vec4(0.5);
const float C_3d0 = 3.0;
const float C_0d24 = 0.24;
const float C_0d26 = 0.26;
const float C_0d27 = 0.27;
const vec3 C_vec3p0d1p = vec3(0.1);
const vec3 C_vec3p0d2p = vec3(0.2);
const int C_2 = 2;
const int C_0 = 0;
const float C_2d5 = 2.5;
const ivec3 C_ivec3p5p = ivec3(5);
const int C_7 = 7;
const int C_4 = 4;
const float C_1d8 = 1.8;
const int C_3 = 3;
const int C_5 = 5;

void main()
{
	highp vec2 H_rfkmnk1 = fma(inf, ing, inch);
	highp ivec2 H_yigdm2 = ivec2(inf);
	highp vec4 color = textureGatherOffset(sArray[index], ubInst[index].p, H_yigdm2);
	highp vec4 color1 = color + C_vec4p0d0p;
	highp vec4 color2 = textureGatherOffsets(sArray[index], H_rfkmnk1, offsets_1);
	highp vec4 color3 = color1 + color2;
	outInst.color = color3;
	highp int Lg_2 = textureSize(bufSamp1);
	highp float H_ywqokl = float(Lg_2);
	vec4 H_29tz9q = vec4(H_ywqokl);
	highp int Lg_3 = textureSize(bufSamp2);
	highp float H_zfwzkb = float(Lg_3);
	vec4 H_jtcw6e = vec4(H_zfwzkb);
	highp vec4 H_tmg2id = H_29tz9q * H_jtcw6e;
	highp int Lg_4 = textureSize(bufSamp3);
	highp float H_0s46rh1 = float(Lg_4);
	vec4 H_jd3i9b1 = vec4(H_0s46rh1);
	highp vec4 H_0qikev = H_jd3i9b1 * H_tmg2id;
	highp int Lg_5 = imageSize(bufSamp4);
	highp float H_lexa7c1 = float(Lg_5);
	vec4 H_k45lki1 = vec4(H_lexa7c1);
	highp vec4 H_45ysfb1 = H_0qikev * H_k45lki1;
	highp int Lg_6 = imageSize(bufSamp5);
	highp float H_yj8yui1 = float(Lg_6);
	vec4 H_g3hesn = vec4(H_yj8yui1);
	highp vec4 H_x7poy9 = H_45ysfb1 * H_g3hesn;
	highp int Lg_7 = imageSize(bufSamp6);
	highp float H_z2e9v81 = float(Lg_7);
	vec4 H_yqcq7n = vec4(H_z2e9v81);
	highp vec4 H_urid191 = H_x7poy9 * H_yqcq7n;
	highp vec4 H_atl2xa1 = texelFetch(bufSamp1, Lg_7);
	highp vec4 H_h75qkx1 = H_atl2xa1 * H_urid191;
	highp ivec4 H_dh1ouc1 = texelFetch(bufSamp2, Lg_7);
	highp vec4 H_66f9mx = vec4(H_dh1ouc1);
	highp vec4 H_e5pv37 = H_66f9mx * H_h75qkx1;
	highp ivec4 H_6kpx1c = ivec4(texelFetch(bufSamp3, Lg_7));
	highp vec4 H_m0xpfo = vec4(H_6kpx1c);
	highp vec4 H_fyk7d1 = H_e5pv37 * H_m0xpfo;
	highp vec4 H_nmnas71 = H_fyk7d1 + color3;
	outInst.color = H_nmnas71;
	highp ivec3 iv = textureSize(CA4, C_1);
	highp ivec3 iv1 = textureSize(CA5, C_1);
	highp ivec3 iv2 = iv + iv1;
	highp ivec3 iv3 = textureSize(CA6, C_1);
	highp ivec3 iv4 = iv2 + iv3;
	highp ivec3 iv5 = textureSize(CA7, C_1);
	highp ivec3 iv6 = iv4 + iv5;
	highp ivec3 iv7 = imageSize(CA1);
	highp ivec3 iv8 = iv6 + iv7;
	highp ivec3 iv9 = imageSize(CA2);
	highp ivec3 iva = iv8 + iv9;
	highp ivec3 ivb = imageSize(CA3);
	highp ivec3 ivc = iva + ivb;
	highp vec3 H_hde89w = vec3(ivc);
	vec4 H_a3dw2n1 = vec4(H_hde89w.x, H_hde89w.y, H_hde89w.z, C_1d0);
	highp vec4 H_4nebdn1 = texture(CA4, C_vec4p0d5p);
	highp vec4 H_v8i73e1 = H_4nebdn1 * H_a3dw2n1;
	highp float H_2eorl7 = texture(CA5, C_vec4p0d5p, C_3d0);
	vec4 H_wtvc7b = vec4(H_2eorl7);
	highp vec4 H_d1zsb5 = H_v8i73e1 * H_wtvc7b;
	highp ivec4 H_ekbbp1 = texture(CA6, C_vec4p0d5p);
	highp vec4 H_ay1qwg = vec4(H_ekbbp1);
	highp vec4 H_874k3m1 = H_ay1qwg * H_d1zsb5;
	highp ivec4 H_zszx85 = ivec4(texture(CA7, C_vec4p0d5p));
	highp vec4 H_lvv8bu1 = vec4(H_zszx85);
	highp vec4 H_q71eyj1 = H_874k3m1 * H_lvv8bu1;
	highp vec4 H_flh258 = textureLod(CA4, C_vec4p0d5p, C_0d24);
	highp vec4 H_4fv8ba1 = H_flh258 * H_q71eyj1;
	highp ivec4 H_fzum841 = textureLod(CA6, C_vec4p0d5p, C_0d26);
	highp vec4 H_swd5rv = vec4(H_fzum841);
	highp vec4 H_maa9mj1 = H_4fv8ba1 * H_swd5rv;
	highp ivec4 H_pcayl01 = ivec4(textureLod(CA7, C_vec4p0d5p, C_0d27));
	highp vec4 H_t6ywbf = vec4(H_pcayl01);
	highp vec4 H_fseoj81 = H_maa9mj1 * H_t6ywbf;
	highp vec4 H_lf9phc = textureGrad(CA4, C_vec4p0d5p, C_vec3p0d1p, C_vec3p0d2p);
	highp vec4 H_l62q1r = H_fseoj81 * H_lf9phc;
	highp ivec4 H_vl4dwn = textureGrad(CA6, C_vec4p0d5p, C_vec3p0d1p, C_vec3p0d2p);
	highp vec4 H_eniryi1 = vec4(H_vl4dwn);
	highp vec4 H_w5j6hw = H_eniryi1 * H_l62q1r;
	highp ivec4 H_0xnjfd = ivec4(textureGrad(CA7, C_vec4p0d5p, C_vec3p0d1p, C_vec3p0d2p));
	highp vec4 H_t6i666 = vec4(H_0xnjfd);
	highp vec4 H_tzbiuc1 = H_t6i666 * H_w5j6hw;
	highp vec4 H_bd785s1 = textureGather(CA4, C_vec4p0d5p);
	highp vec4 H_ztu52i1 = H_bd785s1 * H_tzbiuc1;
	highp vec4 H_7lavnb = textureGather(CA4, C_vec4p0d5p, C_2);
	highp vec4 H_5t4p6g1 = H_7lavnb * H_ztu52i1;
	highp ivec4 H_9xh0a6 = textureGather(CA6, C_vec4p0d5p);
	highp vec4 H_l4nm1w1 = vec4(H_9xh0a6);
	highp vec4 H_0rqyol = H_5t4p6g1 * H_l4nm1w1;
	highp ivec4 H_ymfw2s = textureGather(CA6, C_vec4p0d5p, C_1);
	highp vec4 H_t56auu1 = vec4(H_ymfw2s);
	highp vec4 H_t154xu = H_0rqyol * H_t56auu1;
	highp ivec4 H_ydllmd = ivec4(textureGather(CA7, C_vec4p0d5p));
	highp vec4 H_3ipl0p = vec4(H_ydllmd);
	highp vec4 H_i4e431 = H_3ipl0p * H_t154xu;
	highp ivec4 H_ooduar1 = ivec4(textureGather(CA7, C_vec4p0d5p, C_0));
	highp vec4 H_cf048n1 = vec4(H_ooduar1);
	highp vec4 H_pc85do = H_cf048n1 * H_i4e431;
	highp vec4 H_jf20ca1 = textureGather(CA5, C_vec4p0d5p, C_2d5);
	highp vec4 H_z1vosj1 = H_jf20ca1 * H_pc85do;
	highp vec4 H_58e0mw = H_nmnas71 + H_z1vosj1;
	outInst.color = H_58e0mw;
	highp ivec3 ivd = textureSize(samp2DMSA);
	highp ivec3 ive = textureSize(samp2DMSAi);
	highp ivec3 ivf = ivd + ive;
	highp ivec3 ivg = textureSize(samp2DMSAu);
	highp ivec3 ivh = ivf + ivg;
	highp vec3 H_6qzg0u = vec3(ivh);
	vec4 H_i0ncds = vec4(H_6qzg0u.x, H_6qzg0u.y, H_6qzg0u.z, C_1d0);
	highp vec4 H_zrrw7f = texelFetch(samp2DMSA, C_ivec3p5p, C_2);
	highp vec4 H_0t87zz = H_i0ncds * H_zrrw7f;
	highp ivec4 H_ejdodg = texelFetch(samp2DMSAi, C_ivec3p5p, C_2);
	highp vec4 H_m4b7fm = vec4(H_ejdodg);
	highp vec4 H_7ykb61 = H_0t87zz * H_m4b7fm;
	highp ivec4 H_y3ux271 = ivec4(texelFetch(samp2DMSAu, C_ivec3p5p, C_2));
	highp vec4 H_wecuat = vec4(H_y3ux271);
	highp vec4 H_e134ze = H_7ykb61 * H_wecuat;
	highp vec4 H_6vd2i3 = H_58e0mw + H_e134ze;
	outInst.color = H_6vd2i3;
	highp int H_mjkl0z = imageAtomicAdd(im2Di, P, P.x);
	highp int H_nbx7j2 = int(imageAtomicAdd(im2Du, P, C_7));
	highp int H_jibexl = imageAtomicMin(im2Di, P, C_4);
	highp int H_g61n5q = int(imageAtomicMin(im2Du, P, C_7));
	highp int H_hq1jrg1 = imageAtomicMax(im2Di, P, C_4);
	highp int H_6kaa4s = int(imageAtomicMax(im2Du, P, C_7));
	highp int H_4y5svb1 = imageAtomicAnd(im2Di, P, C_4);
	highp int H_1jbwq31 = int(imageAtomicAnd(im2Du, P, C_7));
	highp int H_u14qg = imageAtomicOr(im2Di, P, C_4);
	highp int H_xozrec1 = int(imageAtomicOr(im2Du, P, C_7));
	highp int H_oo8y65 = imageAtomicXor(im2Di, P, C_4);
	highp int H_99e9xw1 = int(imageAtomicXor(im2Du, P, C_7));
	highp int H_i2kk971 = imageAtomicExchange(im2Di, P, C_4);
	highp int H_lyyarb = int(imageAtomicExchange(im2Du, P, C_7));
	highp float H_ke2fhb = imageAtomicExchange(im2Df, P, C_1d8);
	highp int H_qc97iy1 = imageAtomicCompSwap(im2Di, P, C_3, C_4);
	highp int H_9n52yt = int(imageAtomicCompSwap(im2Du, P, C_5, C_7));
	
}

